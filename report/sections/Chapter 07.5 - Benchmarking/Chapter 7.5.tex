\chapter{Benchmarking} \label{chap:Benchmarking}
To ensure that the developed platform can handle an appropriate amount of users, the Test Runner has been stress tested and benchmarked.
In this chapter we present how these tests and benchmarks have been conducted, and describe the implementation. To conduct the benchmarks, we have utilized BenchmarkDotnet (see \ref{chap:preliminaries}) and defined three components used solely for the benchmarks:
a client component simulating possible Test Runner client behavior, a Benchmark component responsible for orchestrating benchmarks for different Test Runner versions, and a test component ensuring that the client component can contact the Test Runner before running the benchmarks.

\section{Orchestration and Test Runner parameterization}
The benchmark and test components are managed in their own docker containers, and are connected to a network enabling communication between them and the container hosting the Test Runner. 
Information necessary to establish such connection between Test Runner and other components are defined as environmental constants for the containers, and are passed into the relevant Dockerfiles describing the services.
These constants are then shared among the necessary components' Dockerfile, which then use the information to establish a connection to the Test Runner.
For instance, the environmental constants describing the network location of the Test Runner service is passed as arguments to the Dockerfiles describing the tests and the benchmark, as these must both be able to contact the Test Runner service.
These environmental constants also enable easily adjusting Test Runner settings without rebuiding the docker container. Adjustments, such as the size of the queue system and the maximum number of threads the Test Runner can use to test the submitted Haskell code, can thus be changed on a whim. This makes it easy to make adjustments for the Test Runner, and in turn to experiment with different versions for the benchmarks.  
The containers are orchestrated such that the benchmarks starts only if the test container exits successfully --- that is, all the test pass successfully. Thus, wrongly configured containers does not result in misleading benchmark results.

\todo{Create a picture for the orchestration}

\section{Simulating client behavior}


The test project consists of three components: clients, tests, and benchmarks.
The client component provides implementation for client behaviors. Different clients provide different ways of contacting the Test Runner.

The client project detail different client behaviors
The benchmark contain different benchmarks
The test contains test that ensure that the Test Runner can be contacted before running the benchmark.