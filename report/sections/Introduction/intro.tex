Most students attending the \textit{Programming Paradigms} course failed last semester.
This resulted in a survey being sent out, and a student task force being assembled to understand the issues that caused the high failure rate.
Here, many students mentioned not feeling experienced enough with the programming languages used in the course to teach the functional and logical programming paradigms.

Consequently, \aau{} chose to restructure the course entirely.
Rather than teaching many different programming languages within the functional and logical programming paradigms, the course was restructured to focus only on Haskell.
Furthermore, the course now features more practical programming exercises with classroom discussion in-between, rather than traditional lectures followed by a separate exercise session.
Supporting this way of teaching, the course lectures have been moved to a more specialized classroom setup. The classroom has been set up such that it has tables for all student groups, each having a monitor that can be shared between the students. This allows students to work together when solving exercises during a session.
In addition, a primary monitor at the lecture desk enables the lecturer to view and share other groups' monitors such that student solutions can be used for classroom discussions.


\section{Problem Analysis}
Following the restructuring of the \textit{Programming Paradigms} course, new problems arose.
Since students use their own local development environments for programming exercises, other students cannot revisit the discussed exercise solutions created by other groups.
This makes it difficult to reflect on and learn from other students' solutions.
Furthermore, it is difficult to verify whether one's own solution is correct and lives up to the requirements of the exercise.
In fact, it is not uncommon for people to misunderstand an exercise and therefore implement an incorrect solution.
Additionally, the system used to connect to and use the monitors in the classroom does not support any Linux-based operating systems, resulting in many students being unable to share their solutions on the monitor.
Feedback is often slow since students must wait for teaching assistants to answer questions from many groups --- these questions are often the same, or of similar nature.
Often, students end up waiting until the time assigned for the exercise runs out, after which a solution is presented to the whole class.

To summarize, while the new structure of the course has taken steps to improve the learning experience, it still has limitations.
Students often wait for so long that the allocated time runs out and consequently, they never solve the problem themselves.

\section{Existing Solutions}
In order to deal with the aforementioned problems, students sometimes use third-party learning platforms such as Codewars\cite{Codewars}, Coursera\cite{Coursera}, and Codecademy\cite{Codecademy}.
These platforms offer an alternative way of learning programming languages and paradigms to traditional classroom teaching by offering problems the user must solve.
However, the feedback loop for each platform is not necessarily conducive for learning course material.


For example, CodeWars focuses on competitive programming where users compete to solve assorted problems.
When a user submits a problem solution, one or more tests are used to verify whether or not the submission solves the given problem.
However, the problems do not constrain the user to use specific programming language constructs in their solution.
Therefore, the solutions with the highest ratings can include language constructs that are foreign to a new programmer.
This would not be ideal in a university setting where students need to understand and apply specific concepts for each exercise session.


Next, Coursera offers on-demand lectures and exercises created by third parties similar to how a traditional university course might be structured.
However on Coursera, there is no way to ask other people for help if a student gets stuck on an exercise.
Furthermore, feedback on exercises is given in written form by other course participants, meaning there is no way to get feedback from a lecturer or teaching assistant.


Finally, while Codecademy offers instant feedback on problem solutions through tests, Codecademy has its own curriculums. This means that external lecturers have little influence on the curriculum.
While Codecademy does inform the user of problems in their code, this is only limited to compiler errors and test failures.
There is no way to get in-depth feedback on a solution from an expert such as a lecturer.

Despite offering unique approaches to teaching, none of these platforms are suitable as a supplementary platform to the \textit{Programming Paradigms} course.

\section{Problem Statement}
Existing platforms for learning to program are mainly split into three types: Coding exercises, video guides, and online curricula.
AAU could benefit from an application that has been designed specifically of teaching in a university setting.
To address the shortcomings of the current approach used during exercise sessions, an application could be created that enables fast, concrete feedback on exercise submissions for students. Additionally, the application could monitor students' progress and present it to lecturers.
By summarizing the main problems following the switch to the new teaching approach, and the limitations of currently available solutions, an initial problem statement is written.
\begin{displayquote}
    How can a web application ensure fast evaluation of students' exercise solutions?
\end{displayquote}

\section{Solution}
To alleviate the problem defined in the problem statement, a platform supporting evaluation of Haskell code has been developed. This platform evaluates whether a student's Haskell program solves a given problem defined in an exercise. It supports the definition of these exercises and accompanying software tests defining solution criteria for a particular exercise. These software tests are executed using a Haskell interpreter, and the results are presented to the user of the platform on a web based user interface.
Information about submitted solutions are persisted in a database so they can be accessed by users again in the future.
To examine the scalability of the solution, essential parts of the platform have been stress-tested to ensure availability and reliability.

In the following chapters, we describe this platform and how it aims to solve the problem of quickly verifying whether a submitted Haskell program satisfies certain solution criteria defined in test code.
In chapter \ref{chap:preliminaries}, we present the theory and technology necessary to understand the developed solution.
Chapter \ref{chap:Specification} introduces specifications and use cases that the developed solution must satisfy.
Chapter \ref{chap:Design} and \ref{chap:Architecture} detail the design and architecture of the solution in terms of components and user interface.
Chapter \ref{chap:Frontend} and \ref{chap:TestRunner} present a detailed description of key functionality and concepts of the solution.
Chapter \ref{chap:Evaluation} describes the evaluation of the platform in terms of usability and response time. 
Finally, chapters \ref{chap:Discussion} to \ref{chap:Conclusion} discusses the developed platform and the development process.

